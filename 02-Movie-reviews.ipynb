{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Movie Reviews and Bag-of-Words Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üéØ The goal of this challenge is to play with the ***Bag-of-words*** modelling of texts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚úçÔ∏è In the following dataset, we have $2000$ reviews classified either as _\"positive\"_ or _\"negative\"_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-12T11:50:49.072227Z",
     "iopub.status.busy": "2025-08-12T11:50:49.071806Z",
     "iopub.status.idle": "2025-08-12T11:50:52.526187Z",
     "shell.execute_reply": "2025-08-12T11:50:52.524927Z",
     "shell.execute_reply.started": "2025-08-12T11:50:49.072181Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.datasets import fetch_lfw_people\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import cross_validate, train_test_split, GridSearchCV\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from time import time\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "from scipy import stats\n",
    "from tempfile import mkdtemp\n",
    "from shutil import rmtree\n",
    "\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "from sklearn import set_config\n",
    "set_config(display = 'diagram')\n",
    "\n",
    "# Sklearn preprocessing\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.compose import make_column_transformer, make_column_selector, ColumnTransformer\n",
    "from sklearn.ensemble import AdaBoostRegressor, VotingRegressor, GradientBoostingRegressor, StackingRegressor, RandomForestRegressor\n",
    "from sklearn.feature_selection import SelectPercentile, mutual_info_regression, VarianceThreshold, SelectFromModel\n",
    "from sklearn.impute import SimpleImputer, KNNImputer\n",
    "from sklearn.linear_model import Ridge, LinearRegression, LogisticRegression\n",
    "from sklearn.metrics import make_scorer, mean_squared_error, mean_squared_log_error, accuracy_score\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.neighbors import KNeighborsRegressor, KNeighborsClassifier\n",
    "from sklearn.pipeline import make_pipeline, Pipeline\n",
    "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder, OrdinalEncoder, FunctionTransformer, LabelEncoder\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "import string\n",
    "from nltk import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import recall_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-12T11:50:52.551764Z",
     "iopub.status.busy": "2025-08-12T11:50:52.551224Z",
     "iopub.status.idle": "2025-08-12T11:51:00.692424Z",
     "shell.execute_reply": "2025-08-12T11:51:00.690948Z",
     "shell.execute_reply.started": "2025-08-12T11:50:52.551717Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000, 2)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"https://wagon-public-datasets.s3.amazonaws.com/05-Machine-Learning/10-Natural-Language-Processing/movie_reviews.csv\")\n",
    "data.head()\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì **Question (Cleaning Text)** ‚ùì\n",
    "\n",
    "- Write a function `preprocessing` that will clean a sentence and apply it to all our reviews. It should:\n",
    "    - remove whitespace\n",
    "    - lowercase characters\n",
    "    - remove numbers\n",
    "    - remove punctuation\n",
    "    - tokenize\n",
    "    - lemmatize\n",
    "- You can store the cleaned reviews into a column called `clean_reviews`.\n",
    "- Do not remove stopwords in this challenge, we will explain why in the section `3. N-gram modelling`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-12T11:51:00.702515Z",
     "iopub.status.busy": "2025-08-12T11:51:00.701747Z",
     "iopub.status.idle": "2025-08-12T11:51:00.726203Z",
     "shell.execute_reply": "2025-08-12T11:51:00.724780Z",
     "shell.execute_reply.started": "2025-08-12T11:51:00.702450Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def preprocessing(sentence):\n",
    "\n",
    "    # Basic cleaning\n",
    "    sentence = sentence.strip() ## remove whitespaces\n",
    "    sentence = sentence.lower() ## lowercase\n",
    "    sentence = ''.join(char for char in sentence if not char.isdigit()) ## remove numbers\n",
    "\n",
    "    # Advanced cleaning\n",
    "    for punctuation in string.punctuation:\n",
    "        sentence = sentence.replace(punctuation, '') ## remove punctuation\n",
    "\n",
    "    tokenized_sentence = word_tokenize(sentence) ## tokenize\n",
    "    stop_words = set(stopwords.words('english')) ## define stopwords\n",
    "\n",
    "    tokenized_sentence_cleaned = [ ## remove stopwords\n",
    "        w for w in tokenized_sentence if not w in stop_words\n",
    "    ]\n",
    "\n",
    "    lemmatized_v = [\n",
    "        WordNetLemmatizer().lemmatize(word, pos = \"v\")\n",
    "        for word in tokenized_sentence_cleaned\n",
    "    ]\n",
    "\n",
    "    lemmatized_n = [\n",
    "        WordNetLemmatizer().lemmatize(word, pos = \"n\")\n",
    "        for word in lemmatized_v\n",
    "    ]\n",
    "    \n",
    "    lemmatized_a = [\n",
    "        WordNetLemmatizer().lemmatize(word, pos = \"a\")\n",
    "        for word in lemmatized_n\n",
    "    ]\n",
    "\n",
    "    cleaned_sentence = ' '.join(word for word in lemmatized_a)\n",
    "\n",
    "    return cleaned_sentence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-12T11:51:00.730879Z",
     "iopub.status.busy": "2025-08-12T11:51:00.729931Z",
     "iopub.status.idle": "2025-08-12T11:51:36.972416Z",
     "shell.execute_reply": "2025-08-12T11:51:36.971312Z",
     "shell.execute_reply.started": "2025-08-12T11:51:00.730797Z"
    }
   },
   "outputs": [],
   "source": [
    "data['clean_reviews'] = data.reviews.apply(lambda x: preprocessing(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-12T11:51:36.974995Z",
     "iopub.status.busy": "2025-08-12T11:51:36.974315Z",
     "iopub.status.idle": "2025-08-12T11:51:36.989454Z",
     "shell.execute_reply": "2025-08-12T11:51:36.985699Z",
     "shell.execute_reply.started": "2025-08-12T11:51:36.974946Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       plot two teen couple go church party drink dri...\n",
       "1       happy bastard quick movie review damn yk bug g...\n",
       "2       movie like make jade movie viewer thankful inv...\n",
       "3       quest camelot warner bros first featurelength ...\n",
       "4       synopsis mentally unstable man undergo psychot...\n",
       "                              ...                        \n",
       "1995    wow movie everything movie funny dramatic inte...\n",
       "1996    richard gere command actor he always great fil...\n",
       "1997    glorystarring matthew broderick denzel washing...\n",
       "1998    steven spielberg second epic film world war ii...\n",
       "1999    truman trueman burbank perfect name jim carrey...\n",
       "Name: clean_reviews, Length: 2000, dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.clean_reviews"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì **Question (LabelEncoding)**‚ùì\n",
    "\n",
    "LabelEncode your target and store it into a column called `\"target_encoded\"`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-12T11:51:36.992408Z",
     "iopub.status.busy": "2025-08-12T11:51:36.991154Z",
     "iopub.status.idle": "2025-08-12T11:51:37.027031Z",
     "shell.execute_reply": "2025-08-12T11:51:37.023597Z",
     "shell.execute_reply.started": "2025-08-12T11:51:36.992346Z"
    },
    "tags": [
     "challengify"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>reviews</th>\n",
       "      <th>clean_reviews</th>\n",
       "      <th>target_encoded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>neg</td>\n",
       "      <td>plot : two teen couples go to a church party ,...</td>\n",
       "      <td>plot two teen couple go church party drink dri...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>neg</td>\n",
       "      <td>the happy bastard's quick movie review \\ndamn ...</td>\n",
       "      <td>happy bastard quick movie review damn yk bug g...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>neg</td>\n",
       "      <td>it is movies like these that make a jaded movi...</td>\n",
       "      <td>movie like make jade movie viewer thankful inv...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>neg</td>\n",
       "      <td>\" quest for camelot \" is warner bros . ' firs...</td>\n",
       "      <td>quest camelot warner bros first featurelength ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>neg</td>\n",
       "      <td>synopsis : a mentally unstable man undergoing ...</td>\n",
       "      <td>synopsis mentally unstable man undergo psychot...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  target                                            reviews  \\\n",
       "0    neg  plot : two teen couples go to a church party ,...   \n",
       "1    neg  the happy bastard's quick movie review \\ndamn ...   \n",
       "2    neg  it is movies like these that make a jaded movi...   \n",
       "3    neg   \" quest for camelot \" is warner bros . ' firs...   \n",
       "4    neg  synopsis : a mentally unstable man undergoing ...   \n",
       "\n",
       "                                       clean_reviews  target_encoded  \n",
       "0  plot two teen couple go church party drink dri...               0  \n",
       "1  happy bastard quick movie review damn yk bug g...               0  \n",
       "2  movie like make jade movie viewer thankful inv...               0  \n",
       "3  quest camelot warner bros first featurelength ...               0  \n",
       "4  synopsis mentally unstable man undergo psychot...               0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# YOUR CODE HERE\n",
    "target_encode = LabelEncoder()\n",
    "data['target_encoded'] = target_encode.fit_transform(data.target)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-12T11:51:37.031712Z",
     "iopub.status.busy": "2025-08-12T11:51:37.030533Z",
     "iopub.status.idle": "2025-08-12T11:51:37.056023Z",
     "shell.execute_reply": "2025-08-12T11:51:37.051056Z",
     "shell.execute_reply.started": "2025-08-12T11:51:37.031655Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>reviews</th>\n",
       "      <th>clean_reviews</th>\n",
       "      <th>target_encoded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>neg</td>\n",
       "      <td>plot : two teen couples go to a church party ,...</td>\n",
       "      <td>plot two teen couple go church party drink dri...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>neg</td>\n",
       "      <td>the happy bastard's quick movie review \\ndamn ...</td>\n",
       "      <td>happy bastard quick movie review damn yk bug g...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>neg</td>\n",
       "      <td>it is movies like these that make a jaded movi...</td>\n",
       "      <td>movie like make jade movie viewer thankful inv...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>neg</td>\n",
       "      <td>\" quest for camelot \" is warner bros . ' firs...</td>\n",
       "      <td>quest camelot warner bros first featurelength ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>neg</td>\n",
       "      <td>synopsis : a mentally unstable man undergoing ...</td>\n",
       "      <td>synopsis mentally unstable man undergo psychot...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  target                                            reviews  \\\n",
       "0    neg  plot : two teen couples go to a church party ,...   \n",
       "1    neg  the happy bastard's quick movie review \\ndamn ...   \n",
       "2    neg  it is movies like these that make a jaded movi...   \n",
       "3    neg   \" quest for camelot \" is warner bros . ' firs...   \n",
       "4    neg  synopsis : a mentally unstable man undergoing ...   \n",
       "\n",
       "                                       clean_reviews  target_encoded  \n",
       "0  plot two teen couple go church party drink dri...               0  \n",
       "1  happy bastard quick movie review damn yk bug g...               0  \n",
       "2  movie like make jade movie viewer thankful inv...               0  \n",
       "3  quest camelot warner bros first featurelength ...               0  \n",
       "4  synopsis mentally unstable man undergo psychot...               0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Quick check\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Bag-of-Words Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì **Question (NaiveBayes with unigrams)** ‚ùì\n",
    "\n",
    "Using `cross_validate`, score a Multinomial Naive Bayes model trained on a Bag-of-Words representation of the texts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-12T11:51:37.063098Z",
     "iopub.status.busy": "2025-08-12T11:51:37.060567Z",
     "iopub.status.idle": "2025-08-12T11:51:45.040455Z",
     "shell.execute_reply": "2025-08-12T11:51:45.039207Z",
     "shell.execute_reply.started": "2025-08-12T11:51:37.063033Z"
    },
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "count_vectorizer = CountVectorizer()\n",
    "pipe_nb = make_pipeline(\n",
    "    CountVectorizer(),\n",
    "    MultinomialNB()\n",
    ")\n",
    "\n",
    "cv_results = cross_validate(pipe_nb, data.clean_reviews, data.target_encoded, cv=5, scoring=['recall'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-12T11:51:45.042888Z",
     "iopub.status.busy": "2025-08-12T11:51:45.042052Z",
     "iopub.status.idle": "2025-08-12T11:51:45.054979Z",
     "shell.execute_reply": "2025-08-12T11:51:45.052846Z",
     "shell.execute_reply.started": "2025-08-12T11:51:45.042830Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.797"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_results['test_recall'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. N-gram Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üëÄ Remember that we asked you not to remove stopwords. Why? \n",
    "\n",
    "üëâ We will train the Naive Bayes model with bigrams. Hence, in sentence like \"I do not like coriander\", it is important to scan the bigram \"do not\" to detect negativity in this sentence for example."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì **Question (NaiveBayes with bigrams)** ‚ùì\n",
    "\n",
    "Using `cross_validate`, score a Multinomial Naive Bayes model trained on a 2-gram Bag-of-Words representation of the texts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-12T11:53:21.070913Z",
     "iopub.status.busy": "2025-08-12T11:53:21.070361Z",
     "iopub.status.idle": "2025-08-12T11:53:27.082803Z",
     "shell.execute_reply": "2025-08-12T11:53:27.081196Z",
     "shell.execute_reply.started": "2025-08-12T11:53:21.070862Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.82"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer = CountVectorizer(ngram_range = (1,2))\n",
    "naivebayes = MultinomialNB()\n",
    "\n",
    "X_bow = vectorizer.fit_transform(data.clean_reviews)\n",
    "\n",
    "cv_nb = cross_validate(\n",
    "    naivebayes,\n",
    "    X_bow,\n",
    "    data.target_encoded,\n",
    "    scoring = \"accuracy\"\n",
    ")\n",
    "\n",
    "round(cv_nb['test_score'].mean(),2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üèÅ Congratulations! Now, you know how to train a Naive Bayes model on vectorized texts.\n",
    "\n",
    "üíæ Don't forget to¬†`git add/commit/push`¬†your notebook...\n",
    "\n",
    "üöÄ ... and move on to the next challenge!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git add 02-Movie-reviews.ipynb\n",
    "\n",
    "! git commit -m \"ham or spam\"\n",
    "\n",
    "! git push origin master"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
